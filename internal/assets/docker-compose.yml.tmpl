services:
  postgres:
    image: pgvector/pgvector:pg17
    environment:
      - POSTGRES_DB=silobox
      - POSTGRES_USER=silobox
      - POSTGRES_PASSWORD=silobox
    ports:
      - "5432:5432"
    volumes:
      - {{.DataDir}}/postgres:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U silobox -d silobox"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  backend:
    image: eternis/silo-box-backend:{{.ImageTag}}
    ports:
      - "8080:8080"
    volumes:
      - {{.DataDir}}:/app/data
    environment:
      - LLM_BASE_URL={{.LLMBaseURL}}
      - DEFAULT_MODEL={{.DefaultModel}}
      - DATABASE_URL=postgres://silobox:silobox@postgres:5432/silobox?sslmode=disable
      - PORT=8080
      - DATA_DIR=/app/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped

  frontend:
    image: eternis/silo-box-frontend:{{.ImageTag}}
    ports:
      - "{{.Port}}:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - BACKEND_URL=http://backend:8080
    depends_on:
      - backend
    restart: unless-stopped

  inference-engine:
    image: ghcr.io/ggml-org/llama.cpp:full-cuda
    ports:
      - "30000:30000"
    volumes:
      - /data/models:/models:ro
    shm_size: '16g'
    ipc: host
    command:
      - --server
      - -m
      - /models/GLM-4.7-Q4_K_M.gguf
      - -c
      - "32768"
      - -b
      - "2048"
      - -ngl
      - "999"
      - --tensor-split
      - 1,1,1
      - -mg
      - "0"
      - -t
      - "16"
      - --threads-http
      - "8"
      - -fit
      - "off"
      - --host
      - 0.0.0.0
      - --port
      - "30000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1', '2']
              capabilities: [gpu]
    restart: unless-stopped
